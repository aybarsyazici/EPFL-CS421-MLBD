{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cb4ee27-3931-4d90-a8f1-a39470911a89",
   "metadata": {},
   "source": [
    "# Lab 11- Extended Exercises on Time Series Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a130ff2e-9c89-48c9-ac7b-6bf6ab5a6522",
   "metadata": {},
   "source": [
    "You are the Senior Data Scientist in a learning platform called LernTime. Your data science team built a data frame in which each row contains the aggregated features per student (calculated over the first 5 weeks of interactions) and the feature `dropout` indicates whether the student stopped using the platform (1) or not (0) before week 10.\n",
    "\n",
    "The dataframe is in the file `lerntime.csv` and contains the following features:\n",
    "- `video_time`: total video time (in minutes) \n",
    "- `num_sessions` total number of sessions\n",
    "- `num_quizzes`: total number of quizzes attempts\n",
    "- `reading_time`: total theory reading time\n",
    "- `previous_knowledge`: standardized previous knowledge\n",
    "- `browser_speed`: standardized browser speed\n",
    "- `device`:  whether the student logged in using a smartphone (1) or a computer (-1)\n",
    "- `topics`: the topics covered by the user\n",
    "- `education`: current level of education (0: middle school, 1: high school, 2: bachelor, 3: master, 4: Ph.D.).\n",
    "- `dropout`: whether the student stopped using the platform (1) or not (0) before week 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6fbaba-1a0e-445b-8fd8-c9d54bc2b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = \"./../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c186631e-1b9a-412d-93eb-dc442a3be121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'lab-11',\n",
    "    'session_owner': 'mlbd',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222434a0-1950-4704-a312-33e9a10b1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/lerntime_dropout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1700efd2-92a2-42aa-a841-ba2da6a5074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_time</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>num_quizzes</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>previous_knowledge</th>\n",
       "      <th>browser_speed</th>\n",
       "      <th>device</th>\n",
       "      <th>topics</th>\n",
       "      <th>education</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.793303</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>48.186562</td>\n",
       "      <td>1.675972</td>\n",
       "      <td>-0.294704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Locke', 'Descartes', 'Socrates', 'Kant', 'Ni...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.331242</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.945810</td>\n",
       "      <td>0.700522</td>\n",
       "      <td>1.253694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Nietzche', 'Locke', 'Confucius', 'Aristotle'...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.414834</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.611978</td>\n",
       "      <td>1.836716</td>\n",
       "      <td>-1.171352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Plato', 'Locke', 'Nietzche', 'Socrates', 'De...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.556388</td>\n",
       "      <td>47.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.785805</td>\n",
       "      <td>0.209577</td>\n",
       "      <td>-2.043047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Aristotle', 'Socrates', 'Plato', 'Confucius'...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.822362</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.907983</td>\n",
       "      <td>0.265678</td>\n",
       "      <td>-0.754559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Kant', 'Aristotle', 'Confucius', 'Locke', 'P...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_time  num_sessions  num_quizzes  reading_time  previous_knowledge   \n",
       "0   45.793303          99.0         36.0     48.186562            1.675972  \\\n",
       "1   51.331242          57.0         12.0     49.945810            0.700522   \n",
       "2   87.414834          52.0          7.0     20.611978            1.836716   \n",
       "3   58.556388          47.0         31.0     33.785805            0.209577   \n",
       "4   74.822362          58.0         37.0     38.907983            0.265678   \n",
       "\n",
       "   browser_speed  device                                             topics   \n",
       "0      -0.294704     1.0  ['Locke', 'Descartes', 'Socrates', 'Kant', 'Ni...  \\\n",
       "1       1.253694     1.0  ['Nietzche', 'Locke', 'Confucius', 'Aristotle'...   \n",
       "2      -1.171352     1.0  ['Plato', 'Locke', 'Nietzche', 'Socrates', 'De...   \n",
       "3      -2.043047     1.0  ['Aristotle', 'Socrates', 'Plato', 'Confucius'...   \n",
       "4      -0.754559     1.0  ['Kant', 'Aristotle', 'Confucius', 'Locke', 'P...   \n",
       "\n",
       "   education  dropout  \n",
       "0        2.0        0  \n",
       "1        3.0        0  \n",
       "2        4.0        0  \n",
       "3        3.0        0  \n",
       "4        4.0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a7f01b-87fb-4cdd-bb4a-902e37b28040",
   "metadata": {},
   "source": [
    "You decide to explore the different type of users. You want to use your knowledge from your ML4BD course and decide to cluster using Spectral Clustering. \n",
    "In the course, you learnt different ways of constructing the similarity graph, yielding the adjacency matrix serving as an input to the Spectral Clustering. \n",
    "Based on your in-depth exploration of the data, you decide to construct the similarity graph as a  *k-nearest neighbor graph*.\n",
    "\n",
    "Your tasks are to:\n",
    "\n",
    "a) Write a function to compute the k-nearest neighbor graph.\n",
    "\n",
    "b) Cluster the users using Spectral Clustering and your k-nearest neighbor graph function (use 4 neighbors). Use only the features *reading_time* and *topics*. You can assume that optimal number of clusters is 2.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9942acd8-7cff-4367-8497-e232c2b55d38",
   "metadata": {},
   "source": [
    "## a) Computation of the k-nearest neighbor graph \n",
    "Unfortunately, there is no k-nearest neighbor graph implementation available in scikit-learn and you therefore have to implement the function yourself.\n",
    "\n",
    "The function `'k_nearest_neighbor_graph'` takes a similarity matrix `S` as well as the number of neighbors `k` as an input an returns the adjacency matrix `W`.\n",
    "\n",
    "Note that we will not evaluate the coding efficiency of your function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "815a86bf-c8ec-4e71-a39e-df78e45bce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def k_nearest_neighbor_graph(S, k):\n",
    "    # S: similarity matrix\n",
    "    # k: number of neighbors\n",
    "    np_S = np.array(S)\n",
    "    # For each entry in S, keep the k largest values and set the rest to 0\n",
    "    # Hint: use np.argsort and fancy indexing\n",
    "    indexes = np.argsort(np_S, axis=1)[:, -k:]\n",
    "    print(indexes)\n",
    "    print(np.arange(np_S.shape[0])[:, None])\n",
    "    W = np.zeros_like(S)\n",
    "    W[np.arange(np_S.shape[0])[:, None], indexes] = np_S[np.arange(np_S.shape[0])[:, None], indexes]\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ef5ad28-7a1b-4791-a7f8-d25c2205c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0]\n",
      " [3 2 1]\n",
      " [0 1 2]\n",
      " [1 2 3]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[[1.  0.2 0.7 0. ]\n",
      " [0.  1.  0.8 0.4]\n",
      " [0.7 0.8 1.  0. ]\n",
      " [0.  0.4 0.6 1. ]]\n"
     ]
    }
   ],
   "source": [
    "# What np.argsort does is that it returns the indexes of the sorted array\n",
    "# i.e if we have [1, 3, 2] it will return [0, 2, 1]. Which means that the smallest element is at index 0, the second smallest at index 2 and the largest at index 1\n",
    "# If we get the last k elements of this array, we get THE INDEXES of k largest elements of the original array\n",
    "\n",
    "k = 3\n",
    "# Please run this cell for evaluation purposes\n",
    "S = [[1, 0.2, 0.7, 0.1],\n",
    "     [0.2, 1, 0.8, 0.4],\n",
    "     [0.7, 0.8, 1, 0.6],\n",
    "     [0.1, 0.4, 0.6, 1]]\n",
    "\n",
    "a = k_nearest_neighbor_graph(S, k)\n",
    "print(a)\n",
    "#send(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065b4f9c-1231-4e9e-a744-0e45a8f408bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please run this cell for evaluation purposes\n",
    "S = [[1, 0.3, 0.01, 0.1],\n",
    "     [0.3, 1, 0.8, 0.9],\n",
    "     [0.01, 0.8, 1, 0.6],\n",
    "     [0.1, 0.9, 0.6, 1]]\n",
    "\n",
    "k_nearest_neighbor_graph(S, k)\n",
    "a = k_nearest_neighbor_graph(S, k)\n",
    "print(a)\n",
    "send(a, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9964b9b7-356e-474f-b0b5-8d0b1871af1a",
   "metadata": {},
   "source": [
    "## b) Spectral Clustering \n",
    "Perform a spectral clustering using a k-nearest neighbor graph (with 4 neighbors). \n",
    "\n",
    "Use the two features `reading_time` and `topics` only. \n",
    "\n",
    "If you did not manage to solve task a), use a *fully connected graph* as similarity graph to obtain the adjacency matrix `W`. \n",
    "\n",
    "You can assume that the optimal number of clusters is 2. \n",
    "\n",
    "Print the obtained cluster labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73a95f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import spectral_embedding\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import linalg\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "def spectral_clustering(W, n_clusters, random_state=111):\n",
    "    \"\"\"\n",
    "    Spectral clustering\n",
    "    :param W: np array of adjacency matrix\n",
    "    :param n_clusters: number of clusters\n",
    "    :param normed: normalized or unnormalized Laplacian\n",
    "    :return: tuple (kmeans, proj_X, eigenvals_sorted)\n",
    "        WHERE\n",
    "        kmeans scikit learn clustering object\n",
    "        proj_X is np array of transformed data points\n",
    "        eigenvals_sorted is np array with ordered eigenvalues \n",
    "        \n",
    "    \"\"\"\n",
    "    # Compute eigengap heuristic\n",
    "    L = laplacian(W, normed=True)\n",
    "    eigenvals, _ = linalg.eig(L)\n",
    "    eigenvals = np.real(eigenvals)\n",
    "    eigenvals_sorted = eigenvals[np.argsort(eigenvals)]\n",
    "\n",
    "    # Create embedding\n",
    "    random_state = np.random.RandomState(random_state)\n",
    "    proj_X = spectral_embedding(W, n_components=n_clusters,\n",
    "                              random_state=random_state,\n",
    "                              drop_first=False)\n",
    "\n",
    "    # Cluster the points using k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state = random_state)\n",
    "    kmeans.fit(proj_X)\n",
    "\n",
    "    return kmeans, proj_X, eigenvals_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57833bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/75/94jyvgc92_gcwmzgrg36xfd00000gn/T/ipykernel_19910/491770663.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  topics_np = np.array(topics)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reading_time = df['reading_time'].values\n",
    "topics = df['topics'].values\n",
    "# Convert topics to list of lists\n",
    "topics = [eval(t) for t in topics]\n",
    "topics_np = np.array(topics)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "199302a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Topics is a set so we can use the Jaccard similarity \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m jaccard\n\u001b[0;32m----> 7\u001b[0m topic_similarity \u001b[39m=\u001b[39m pairwise_kernels(topics_np\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m), metric\u001b[39m=\u001b[39;49mjaccard)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2205\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[0;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown kernel \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m metric)\n\u001b[0;32m-> 2205\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1599\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pairwise_callable\u001b[39m(X, Y, metric, force_all_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m   1598\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Handle the callable case for pairwise_{distances,kernels}.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1599\u001b[0m     X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite)\n\u001b[1;32m   1601\u001b[0m     \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n\u001b[1;32m   1602\u001b[0m         \u001b[39m# Only calculate metric for upper triangle\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m         out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:146\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m     dtype \u001b[39m=\u001b[39m dtype_float\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m Y \u001b[39mis\u001b[39;00m X \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    147\u001b[0m         X,\n\u001b[1;32m    148\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    149\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    150\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    151\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    152\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    162\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Reading time similarity matrix we can use Gaussian kernel use pairwise_kernels from sklearn.metrics.pairwise\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "reading_similarity = pairwise_kernels(reading_time.reshape(-1,1), metric='rbf')\n",
    "print(reading_similarity.shape)\n",
    "# Topics is a set so we can use the Jaccard similarity \n",
    "from scipy.spatial.distance import jaccard\n",
    "topic_similarity = pairwise_kernels(topics_np.reshape(-1,1), metric=jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e045e0-da50-4336-8879-02cc37e2c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = []\n",
    "send(cluster_labels, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
